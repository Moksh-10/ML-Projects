{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T12:16:32.593379Z",
     "start_time": "2024-12-07T12:16:31.519198Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:59:45.589923Z",
     "start_time": "2024-12-07T13:59:45.574092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor((127.48, -40.1, 0., 89.74, 124.38, -39.1, 126.48, 21.2, -35.99, 124.16,\n",
    "   5.92,  41.68,  23.6,  -26.4,  -21.51, -20.6,   94.49,  85.07,  70.11 , 76.91))\n",
    "a, a.shape"
   ],
   "id": "19882124a164c0a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([127.4800, -40.1000,   0.0000,  89.7400, 124.3800, -39.1000, 126.4800,\n",
       "          21.2000, -35.9900, 124.1600,   5.9200,  41.6800,  23.6000, -26.4000,\n",
       "         -21.5100, -20.6000,  94.4900,  85.0700,  70.1100,  76.9100]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:59:47.618852Z",
     "start_time": "2024-12-07T13:59:47.615360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def asymmetric_quant(x: torch.Tensor, n: int):\n",
    "    alpha = torch.max(x)\n",
    "    beta = torch.min(x)\n",
    "    s = (alpha - beta) / (2**n - 1)\n",
    "    z = torch.round(-1 * (beta / s))\n",
    "    xq = torch.round(x/s) + z\n",
    "    xq = torch.clamp(xq, 0, 2**n -1)\n",
    "    \n",
    "    xf = s * (xq - z)\n",
    "    \n",
    "    return xq, xf\n",
    "    # return xq"
   ],
   "id": "f409eae6da109c20",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:59:47.799126Z",
     "start_time": "2024-12-07T13:59:47.793207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b, c = asymmetric_quant(a, 8)\n",
    "b, b.shape, c, c.shape"
   ],
   "id": "62a3431559fafe1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([255.,   0.,  61., 198., 250.,   2., 253.,  93.,   6., 250.,  70., 124.,\n",
       "          97.,  21.,  28.,  30., 205., 190., 168., 178.]),\n",
       " torch.Size([20]),\n",
       " tensor([127.4922, -40.0878,   0.0000,  90.0332, 124.2064, -38.7734, 126.1779,\n",
       "          21.0296, -36.1447, 124.2064,   5.9146,  41.4021,  23.6584, -26.2871,\n",
       "         -21.6868, -20.3725,  94.6334,  84.7758,  70.3179,  76.8896]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:00:12.682453Z",
     "start_time": "2024-12-07T14:00:12.678611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss(x: torch.Tensor, y: torch.Tensor):\n",
    "    z = torch.mean((x-y)**2)\n",
    "    return z.type_as(x)"
   ],
   "id": "ed18520b19ff0a85",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:00:12.857357Z",
     "start_time": "2024-12-07T14:00:12.852764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gg = torch.tensor((1, 2), dtype=torch.float)\n",
    "# ff = torch.tensor((4, 5), dtype=torch.float)\n",
    "hh = loss(a, c)\n",
    "hh"
   ],
   "id": "6ca2ea20e31a5fec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0348)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:00:16.102677Z",
     "start_time": "2024-12-07T14:00:16.098803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def symmetric_quant(x: torch.Tensor, n: int):\n",
    "    alpha = torch.max(torch.abs(x))\n",
    "    s = alpha / (2**(n-1) -1)\n",
    "    xq = torch.round(x / s)\n",
    "    xq = torch.clamp(xq, -(2**(n-1) - 1), 2**(n-1) -1)\n",
    "    \n",
    "    xf = s * xq\n",
    "    \n",
    "    return xq, xf"
   ],
   "id": "8e85fdbbdb1e3422",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:00:16.331431Z",
     "start_time": "2024-12-07T14:00:16.325572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = symmetric_quant(a, 8)\n",
    "x, y"
   ],
   "id": "6c513243cea14ac0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([127., -40.,   0.,  89., 124., -39., 126.,  21., -36., 124.,   6.,  42.,\n",
       "          24., -26., -21., -21.,  94.,  85.,  70.,  77.]),\n",
       " tensor([127.4800, -40.1512,   0.0000,  89.3364, 124.4687, -39.1474, 126.4762,\n",
       "          21.0794, -36.1361, 124.4687,   6.0227,  42.1587,  24.0907, -26.0983,\n",
       "         -21.0794, -21.0794,  94.3553,  85.3213,  70.2646,  77.2910]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T14:00:16.535907Z",
     "start_time": "2024-12-07T14:00:16.530824Z"
    }
   },
   "cell_type": "code",
   "source": "loss(a, y)",
   "id": "5917af043916025e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0772)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:59:48.816943Z",
     "start_time": "2024-12-07T13:59:48.814979Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1d92de92ede786bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:50:16.137040Z",
     "start_time": "2024-12-08T13:50:15.836178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.randn(32, 512, 8, 32)\n",
    "b = torch.randn(64, 256)\n",
    "c = a * b\n",
    "c.shape"
   ],
   "id": "9f43f738f9ae91e1",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (256) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m a \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m32\u001B[39m)\n\u001B[1;32m      2\u001B[0m b \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m256\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m c \u001B[38;5;241m=\u001B[39m \u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\n\u001B[1;32m      4\u001B[0m c\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (32) must match the size of tensor b (256) at non-singleton dimension 3"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:01:25.344454Z",
     "start_time": "2024-12-08T14:01:25.322502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# \n",
    "# class LinformerSelfAttention(nn.Module):\n",
    "#     def __init__(self, embed_dim, seq_len, num_heads, k):\n",
    "#         \"\"\"\n",
    "#         Linformer Self-Attention Module.\n",
    "#         \n",
    "#         Args:\n",
    "#             embed_dim (int): Dimension of the embeddings.\n",
    "#             seq_len (int): Input sequence length.\n",
    "#             num_heads (int): Number of attention heads.\n",
    "#             k (int): Dimension to project the sequence length (low-rank approximation).\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads.\"\n",
    "#         \n",
    "#         self.embed_dim = embed_dim\n",
    "#         self.seq_len = seq_len\n",
    "#         self.num_heads = num_heads\n",
    "#         self.k = k\n",
    "#         self.head_dim = embed_dim // num_heads\n",
    "# \n",
    "#         # Projections for Query, Key, Value\n",
    "#         self.query_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.key_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.value_proj = nn.Linear(embed_dim, embed_dim)\n",
    "# \n",
    "#         # Low-rank approximation matrix\n",
    "#         self.proj_matrix = nn.Parameter(torch.randn(seq_len, k))  # Learnable projection matrix\n",
    "#         \n",
    "#         # Final output projection\n",
    "#         self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Forward pass of Linformer Self-Attention.\n",
    "#         \n",
    "#         Args:\n",
    "#             x (torch.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n",
    "#         \n",
    "#         Returns:\n",
    "#             torch.Tensor: Output tensor of shape (batch_size, seq_len, embed_dim).\n",
    "#         \"\"\"\n",
    "#         batch_size, seq_len, embed_dim = x.shape\n",
    "#         print(f\"Input shape: {x.shape}\")  # Debugging: Input dimensions\n",
    "#         \n",
    "#         # Project input to Query, Key, Value\n",
    "#         Q = self.query_proj(x)  # (batch_size, seq_len, embed_dim)\n",
    "#         K = self.key_proj(x)    # (batch_size, seq_len, embed_dim)\n",
    "#         V = self.value_proj(x)  # (batch_size, seq_len, embed_dim)\n",
    "#         print(f\"Query shape: {Q.shape}, Key shape: {K.shape}, Value shape: {V.shape}\")\n",
    "#         \n",
    "#         # Reshape for multi-head attention\n",
    "#         Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         print(f\"Reshaped Query shape: {Q.shape}, Reshaped Key shape: {K.shape}, Reshaped Value shape: {V.shape}\")\n",
    "#         \n",
    "#         # Project sequence length of K and V using the projection matrix\n",
    "#         K_proj = torch.matmul(self.proj_matrix.T, K.transpose(2, 3))  # (batch_size, num_heads, k, head_dim)\n",
    "#         print(\"projection\")\n",
    "#         print(self.proj_matrix.shape, self.proj_matrix.T.shape, K.transpose(2, 3).shape)\n",
    "#         V_proj = torch.matmul(self.proj_matrix.T, V.transpose(2, 3))  # (batch_size, num_heads, k, head_dim)\n",
    "#         print(f\"Projected Key shape: {K_proj.shape}, Projected Value shape: {V_proj.shape}\")\n",
    "#         \n",
    "#         # Compute scaled dot-product attention\n",
    "#         attention_scores = torch.matmul(Q, K_proj.transpose(-1, -2)) / (self.head_dim ** 0.5)  # (batch_size, num_heads, seq_len, k)\n",
    "#         attention_weights = torch.softmax(attention_scores, dim=-1)          # (batch_size, num_heads, seq_len, k)\n",
    "#         print(f\"Attention scores shape: {attention_scores.shape}, Attention weights shape: {attention_weights.shape}\")\n",
    "#         \n",
    "#         # Weighted sum of values\n",
    "#         attention_output = torch.matmul(attention_weights, V_proj)          # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         print(f\"Attention output shape (per head): {attention_output.shape}\")\n",
    "#         \n",
    "#         # Concatenate heads and project\n",
    "#         attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)\n",
    "#         print(f\"Concatenated output shape: {attention_output.shape}\")\n",
    "#         \n",
    "#         output = self.out_proj(attention_output)  # (batch_size, seq_len, embed_dim)\n",
    "#         print(f\"Output shape after final projection: {output.shape}\")\n",
    "#         \n",
    "#         return output\n",
    "# \n",
    "# # Test the Linformer Self-Attention\n",
    "# batch_size = 2\n",
    "# seq_len = 16\n",
    "# embed_dim = 64\n",
    "# num_heads = 4\n",
    "# k = 8\n",
    "# \n",
    "# x = torch.rand(batch_size, seq_len, embed_dim)  # Dummy input\n",
    "# linformer = LinformerSelfAttention(embed_dim, seq_len, num_heads, k)\n",
    "# output = linformer(x)\n"
   ],
   "id": "6d2220aa79d066bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 16, 64])\n",
      "Query shape: torch.Size([2, 16, 64]), Key shape: torch.Size([2, 16, 64]), Value shape: torch.Size([2, 16, 64])\n",
      "Reshaped Query shape: torch.Size([2, 4, 16, 16]), Reshaped Key shape: torch.Size([2, 4, 16, 16]), Reshaped Value shape: torch.Size([2, 4, 16, 16])\n",
      "projection\n",
      "torch.Size([16, 8]) torch.Size([8, 16]) torch.Size([2, 4, 16, 16])\n",
      "Projected Key shape: torch.Size([2, 4, 8, 16]), Projected Value shape: torch.Size([2, 4, 8, 16])\n",
      "Attention scores shape: torch.Size([2, 4, 16, 8]), Attention weights shape: torch.Size([2, 4, 16, 8])\n",
      "Attention output shape (per head): torch.Size([2, 4, 16, 16])\n",
      "Concatenated output shape: torch.Size([2, 16, 64])\n",
      "Output shape after final projection: torch.Size([2, 16, 64])\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:34:41.741913Z",
     "start_time": "2024-12-09T04:28:09.647755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class a(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.m1(x)\n",
    "        return x\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'    \n",
    "\n",
    "data = datasets.MNIST(\"/Users/mokshagrawal/Documents/machine-learning/quantization/root\", transform=transforms.ToTensor(), train=True, download=True)\n",
    "loader = DataLoader(data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = a().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "for e in range(20):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    loop = tqdm(enumerate(loader))\n",
    "    for batch_idx, (x, y) in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loss_sum += loss.item()\n",
    "    loss_sum /= len(loader)    \n",
    "    print(f'epoch: {e+1}/ loss: {loss_sum:.4f}')    \n",
    "\n",
    "for e in range(3):\n",
    "    model.eval()\n",
    "    c = 0\n",
    "    t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (x, y) in tqdm(enumerate(loader)):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            _, just = torch.max(y_pred, dim=1)\n",
    "            t += y.size(0)\n",
    "            c += (just == y).sum().item()\n",
    "        print(f'epoch: {e+1}/ acc: {c/t *100:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print(os.path.getsize('model.pth')/1e3)"
   ],
   "id": "cb9522680bd0ef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4525120.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/train-images-idx3-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 101748.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1094899.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1651111.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/mokshagrawal/Documents/machine-learning/quantization/root/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:23, 40.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/ loss: 0.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:17, 54.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/ loss: 0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:15, 59.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/ loss: 0.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:23, 39.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4/ loss: 0.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:20, 45.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5/ loss: 0.0507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:22, 41.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6/ loss: 0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:23, 39.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7/ loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:17, 54.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8/ loss: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:12, 75.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9/ loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:10, 86.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/ loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:18, 51.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11/ loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:19, 47.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12/ loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:14, 64.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13/ loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:18, 51.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14/ loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:11, 81.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15/ loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:12, 72.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16/ loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:14, 64.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17/ loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:15, 60.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18/ loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:16, 56.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19/ loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:17, 53.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20/ loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:07, 119.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/ acc: 99.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:06, 153.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/ acc: 99.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:08, 114.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/ acc: 99.93%\n",
      "2145.588\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:34:58.140748Z",
     "start_time": "2024-12-09T04:34:58.119638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model):\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    for e in range(20):\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        loop = tqdm(enumerate(loader))\n",
    "        for batch_idx, (x, y) in loop:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            loss_sum += loss.item()\n",
    "        loss_sum /= len(loader)    \n",
    "        print(f'epoch: {e+1}/ loss: {loss_sum:.4f}')  \n",
    "        \n",
    "def eval(model):\n",
    "    for e in range(3):\n",
    "        model.eval()\n",
    "        c = 0\n",
    "        t = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (x, y) in tqdm(enumerate(loader)):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                _, just = torch.max(y_pred, dim=1)\n",
    "                t += y.size(0)\n",
    "                c += (just == y).sum().item()\n",
    "            print(f'epoch: {e+1}/ acc: {c/t *100:.2f}%')        "
   ],
   "id": "286a8395c7c10616",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:39:28.238472Z",
     "start_time": "2024-12-09T04:38:51.821037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class aq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.o1 = torch.quantization.QuantStub()\n",
    "        self.m1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        self.o2 = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.o1(x)\n",
    "        x = self.m1(x)\n",
    "        x = self.o2(x)\n",
    "        return x\n",
    "\n",
    "model2 = aq().to(device)  \n",
    "model2.load_state_dict(model.state_dict())\n",
    "model2.eval()\n",
    "\n",
    "model2.qconfig = torch.ao.quantization.default_qconfig\n",
    "model2 = torch.ao.quantization.prepare(model2)\n",
    "print(model2)\n",
    "\n",
    "for e in range(3):\n",
    "    model2.eval()\n",
    "    c = 0\n",
    "    t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (x, y) in tqdm(enumerate(loader)):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model2(x)\n",
    "            _, just = torch.max(y_pred, dim=1)\n",
    "            t += y.size(0)\n",
    "            c += (just == y).sum().item()\n",
    "        print(f'epoch: {e+1}/ acc: {c/t *100:.2f}%')\n",
    "\n",
    "print(model2)        \n",
    "model2 = torch.ao.quantization.convert(model2)\n",
    "print(model2)\n",
    "# print(torch.int_repr(model2.linear1.weight()))\n",
    "# print(torch.dequantize(model2.linear1.weight()))\n",
    "# torch.save(model2.state_dict(), 'model2.pth')\n",
    "# print(os.path.getsize('model2.pth')/1e3)\n",
    "# train(model2)"
   ],
   "id": "829511c2673ed35e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aq(\n",
      "  (o1): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (m1): Sequential(\n",
      "    (0): Linear(\n",
      "      in_features=784, out_features=512, bias=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Linear(\n",
      "      in_features=512, out_features=256, bias=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): Linear(\n",
      "      in_features=256, out_features=10, bias=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    )\n",
      "  )\n",
      "  (o2): DeQuantStub()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:08, 113.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/ acc: 99.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:14, 65.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/ acc: 99.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:13, 71.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/ acc: 99.93%\n",
      "aq(\n",
      "  (o1): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=1.0)\n",
      "  )\n",
      "  (m1): Sequential(\n",
      "    (0): Linear(\n",
      "      in_features=784, out_features=512, bias=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=-10.2401123046875, max_val=7.791010856628418)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Linear(\n",
      "      in_features=512, out_features=256, bias=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=-14.952836036682129, max_val=15.126261711120605)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): Linear(\n",
      "      in_features=256, out_features=10, bias=True\n",
      "      (activation_post_process): MinMaxObserver(min_val=-74.66053009033203, max_val=48.738040924072266)\n",
      "    )\n",
      "  )\n",
      "  (o2): DeQuantStub()\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Didn't find engine for operation quantized::linear_prepack NoQEngine",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[78], line 43\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/ acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;241m/\u001B[39mt\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(model2)        \n\u001B[0;32m---> 43\u001B[0m model2 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mao\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(model2)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# print(torch.int_repr(model2.linear1.weight()))\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# print(torch.dequantize(model2.linear1.weight()))\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:553\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inplace:\n\u001B[1;32m    552\u001B[0m     module \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(module)\n\u001B[0;32m--> 553\u001B[0m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remove_qconfig:\n\u001B[1;32m    557\u001B[0m     _remove_qconfig(module)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:591\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    586\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, mod \u001B[38;5;129;01min\u001B[39;00m module\u001B[38;5;241m.\u001B[39mnamed_children():\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;66;03m# both fused modules and observed custom modules are\u001B[39;00m\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;66;03m# swapped as one unit\u001B[39;00m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[0;32m--> 591\u001B[0m         \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# inplace\u001B[39;49;00m\n\u001B[1;32m    592\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mis_reference\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:593\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001B[0m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mod, _FusedModule) \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    590\u001B[0m        type_before_parametrizations(mod) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m custom_module_class_mapping:\n\u001B[1;32m    591\u001B[0m         _convert(mod, mapping, \u001B[38;5;28;01mTrue\u001B[39;00m,  \u001B[38;5;66;03m# inplace\u001B[39;00m\n\u001B[1;32m    592\u001B[0m                  is_reference, convert_custom_config_dict)\n\u001B[0;32m--> 593\u001B[0m     reassign[name] \u001B[38;5;241m=\u001B[39m \u001B[43mswap_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapping\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_module_class_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m reassign\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    596\u001B[0m     module\u001B[38;5;241m.\u001B[39m_modules[key] \u001B[38;5;241m=\u001B[39m value\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:626\u001B[0m, in \u001B[0;36mswap_module\u001B[0;34m(mod, mapping, custom_module_class_mapping)\u001B[0m\n\u001B[1;32m    624\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m qmod\u001B[38;5;241m.\u001B[39mfrom_float(mod, weight_qparams)\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 626\u001B[0m         new_mod \u001B[38;5;241m=\u001B[39m \u001B[43mqmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_float\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    627\u001B[0m     swapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m swapped:\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;66;03m# Preserve module's pre forward hooks. They'll be called on quantized input\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:277\u001B[0m, in \u001B[0;36mLinear.from_float\u001B[0;34m(cls, mod)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mqint8, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeight observer must have dtype torch.qint8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    276\u001B[0m qweight \u001B[38;5;241m=\u001B[39m _quantize_weight(mod\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mfloat(), weight_post_process)\n\u001B[0;32m--> 277\u001B[0m qlinear \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m              \u001B[49m\u001B[43mmod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m              \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m qlinear\u001B[38;5;241m.\u001B[39mset_weight_bias(qweight, mod\u001B[38;5;241m.\u001B[39mbias)\n\u001B[1;32m    281\u001B[0m qlinear\u001B[38;5;241m.\u001B[39mscale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(act_scale)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:151\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[0;34m(self, in_features, out_features, bias_, dtype)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnsupported dtype specified for quantized Linear!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m \u001B[43mLinearPackedParams\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params\u001B[38;5;241m.\u001B[39mset_weight_bias(qweight, bias)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:27\u001B[0m, in \u001B[0;36mLinearPackedParams.__init__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m     26\u001B[0m     wq \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_weight_bias\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/ao/nn/quantized/modules/linear.py:32\u001B[0m, in \u001B[0;36mLinearPackedParams.set_weight_bias\u001B[0;34m(self, weight, bias)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_weight_bias\u001B[39m(\u001B[38;5;28mself\u001B[39m, weight: torch\u001B[38;5;241m.\u001B[39mTensor, bias: Optional[torch\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mqint8:\n\u001B[0;32m---> 32\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantized\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_prepack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_packed_params \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mquantized\u001B[38;5;241m.\u001B[39mlinear_prepack_fp16(weight, bias)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_ops.py:755\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    750\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    751\u001B[0m     \u001B[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001B[39;00m\n\u001B[1;32m    752\u001B[0m     \u001B[38;5;66;03m# is still callable from JIT\u001B[39;00m\n\u001B[1;32m    753\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    754\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Didn't find engine for operation quantized::linear_prepack NoQEngine"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:41:02.808718Z",
     "start_time": "2024-12-09T04:41:02.778649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(model2.state_dict(), 'model2.pth')\n",
    "print(os.path.getsize('model2.pth')/1e3)"
   ],
   "id": "9a0f1bc6d5f1021e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149.066\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:44:25.187443Z",
     "start_time": "2024-12-09T04:44:25.124367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.quantized as nnq\n",
    "from torch.quantization import get_default_qconfig, prepare, convert\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "model2 = convert(model2)\n",
    "print(model2)"
   ],
   "id": "a7fbf44fda16604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aq(\n",
      "  (o1): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (m1): Sequential(\n",
      "    (0): QuantizedLinear(in_features=784, out_features=512, scale=0.14197735488414764, zero_point=72, qscheme=torch.per_tensor_affine)\n",
      "    (1): ReLU()\n",
      "    (2): QuantizedLinear(in_features=512, out_features=256, scale=0.2368432879447937, zero_point=63, qscheme=torch.per_tensor_affine)\n",
      "    (3): ReLU()\n",
      "    (4): QuantizedLinear(in_features=256, out_features=10, scale=0.9716423153877258, zero_point=77, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (o2): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:46:43.552485Z",
     "start_time": "2024-12-09T04:46:43.513578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.int_repr(model2.m1[0].weight()))\n",
    "print(torch.dequantize(model2.m1[0].weight()))\n",
    "torch.save(model2.state_dict(), 'model2.pth')\n",
    "print(os.path.getsize('model2.pth')/1e3)\n",
    "# train(model2)"
   ],
   "id": "5f2a57e1310bb318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3,   7,  10,  ...,  -2,   7,  -6],\n",
      "        [  6,  -5, -11,  ...,   5,   4,   6],\n",
      "        [  1,  -1,   3,  ...,   8,  -1,  -8],\n",
      "        ...,\n",
      "        [ -2,  -4,   8,  ...,  -6,  -8,   8],\n",
      "        [ 10,  -3,   1,  ...,   4,  -5,  -2],\n",
      "        [  3,   4,   6,  ...,  -6,   9,   5]], dtype=torch.int8)\n",
      "tensor([[ 0.0094,  0.0219,  0.0313,  ..., -0.0063,  0.0219, -0.0188],\n",
      "        [ 0.0188, -0.0157, -0.0345,  ...,  0.0157,  0.0125,  0.0188],\n",
      "        [ 0.0031, -0.0031,  0.0094,  ...,  0.0251, -0.0031, -0.0251],\n",
      "        ...,\n",
      "        [-0.0063, -0.0125,  0.0251,  ..., -0.0188, -0.0251,  0.0251],\n",
      "        [ 0.0313, -0.0094,  0.0031,  ...,  0.0125, -0.0157, -0.0063],\n",
      "        [ 0.0094,  0.0125,  0.0188,  ..., -0.0188,  0.0282,  0.0157]])\n",
      "542.874\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:06:30.258382Z",
     "start_time": "2024-12-09T05:06:12.334087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for e in range(3):\n",
    "    model2.eval()\n",
    "    c = 0\n",
    "    t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (x, y) in tqdm(enumerate(loader)):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model2(x)\n",
    "            _, just = torch.max(y_pred, dim=1)\n",
    "            t += y.size(0)\n",
    "            c += (just == y).sum().item()\n",
    "        print(f'epoch: {e+1}/ acc: {c/t *100:.2f}%')"
   ],
   "id": "4944265bd044f109",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:06, 136.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/ acc: 99.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:05, 167.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/ acc: 99.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:05, 178.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/ acc: 99.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:13:25.395407Z",
     "start_time": "2024-12-09T05:13:25.355731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class qat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.o1 = torch.quantization.QuantStub()\n",
    "        self.m1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        self.o2 = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.o1(x)\n",
    "        x = self.m1(x)\n",
    "        x = self.o2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model3 = qat().to(device)\n",
    "\n",
    "model3.qconfig = torch.ao.quantization.default_qconfig\n",
    "model3.train()\n",
    "model3 = torch.ao.quantization.prepare_qat(model3)\n",
    "print(model3)"
   ],
   "id": "46e5c91eca9d2f38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qat(\n",
      "  (o1): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (m1): Sequential(\n",
      "    (0): Linear(\n",
      "      in_features=784, out_features=512, bias=True\n",
      "      (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Linear(\n",
      "      in_features=512, out_features=256, bias=True\n",
      "      (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): Linear(\n",
      "      in_features=256, out_features=10, bias=True\n",
      "      (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    )\n",
      "  )\n",
      "  (o2): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:15:03.481572Z",
     "start_time": "2024-12-09T05:14:52.897893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model3.parameters(), lr=3e-4)\n",
    "\n",
    "for e in range(1):\n",
    "    # model3.train()\n",
    "    loss_sum = 0\n",
    "    loop = tqdm(enumerate(loader))\n",
    "    for batch_idx, (x, y) in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model3(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loss_sum += loss.item()\n",
    "    loss_sum /= len(loader)    \n",
    "    print(f'epoch: {e+1}/ loss: {loss_sum:.4f}')   "
   ],
   "id": "dc5ee4c882bbc0a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:10, 89.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/ loss: 0.3581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:15:21.354777Z",
     "start_time": "2024-12-09T05:15:21.339127Z"
    }
   },
   "cell_type": "code",
   "source": "print(model3)",
   "id": "4b209d45292e627c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qat(\n",
      "  (o1): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=1.0)\n",
      "  )\n",
      "  (m1): Sequential(\n",
      "    (0): Linear(\n",
      "      in_features=784, out_features=512, bias=True\n",
      "      (weight_fake_quant): MinMaxObserver(min_val=-0.15922757983207703, max_val=0.11339440196752548)\n",
      "      (activation_post_process): MinMaxObserver(min_val=-5.275387763977051, max_val=5.154850482940674)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Linear(\n",
      "      in_features=512, out_features=256, bias=True\n",
      "      (weight_fake_quant): MinMaxObserver(min_val=-0.16703025996685028, max_val=0.16207362711429596)\n",
      "      (activation_post_process): MinMaxObserver(min_val=-8.715311050415039, max_val=9.392265319824219)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): Linear(\n",
      "      in_features=256, out_features=10, bias=True\n",
      "      (weight_fake_quant): MinMaxObserver(min_val=-0.13709521293640137, max_val=0.11249437183141708)\n",
      "      (activation_post_process): MinMaxObserver(min_val=-18.374143600463867, max_val=18.19473648071289)\n",
      "    )\n",
      "  )\n",
      "  (o2): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:16:34.326460Z",
     "start_time": "2024-12-09T05:16:34.292382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model3.eval()\n",
    "\n",
    "\n",
    "model3 = torch.ao.quantization.convert(model3)\n",
    "print(model3)"
   ],
   "id": "ec8dfe0a2c7e5046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qat(\n",
      "  (o1): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (m1): Sequential(\n",
      "    (0): QuantizedLinear(in_features=784, out_features=512, scale=0.08212786167860031, zero_point=64, qscheme=torch.per_tensor_affine)\n",
      "    (1): ReLU()\n",
      "    (2): QuantizedLinear(in_features=512, out_features=256, scale=0.1425793468952179, zero_point=61, qscheme=torch.per_tensor_affine)\n",
      "    (3): ReLU()\n",
      "    (4): QuantizedLinear(in_features=256, out_features=10, scale=0.28794392943382263, zero_point=64, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (o2): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:17:04.665883Z",
     "start_time": "2024-12-09T05:17:04.658006Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.int_repr(model3.m1[0].weight()))",
   "id": "148747b59a081a02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 16,  20,  -6,  ...,   1, -28, -16],\n",
      "        [-24,   8,  -2,  ..., -17,  21,  22],\n",
      "        [ 23,   0,  23,  ..., -20,  -7,  13],\n",
      "        ...,\n",
      "        [-25,  -7,  27,  ...,  -2, -20,  23],\n",
      "        [  0,  25,  -3,  ..., -19,  16,  -8],\n",
      "        [-23,  -3,  17,  ...,  14,  -3,  -3]], dtype=torch.int8)\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T05:17:42.235370Z",
     "start_time": "2024-12-09T05:17:25.299987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for e in range(3):\n",
    "    # model2.eval()\n",
    "    c = 0\n",
    "    t = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (x, y) in tqdm(enumerate(loader)):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model3(x)\n",
    "            _, just = torch.max(y_pred, dim=1)\n",
    "            t += y.size(0)\n",
    "            c += (just == y).sum().item()\n",
    "        print(f'epoch: {e+1}/ acc: {c/t *100:.2f}%')"
   ],
   "id": "5b37e5baec489d22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "938it [00:06, 153.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/ acc: 95.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:05, 177.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/ acc: 95.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "938it [00:05, 173.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3/ acc: 95.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3aa9830ae30e1384"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
